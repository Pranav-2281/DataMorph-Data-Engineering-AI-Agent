<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Group 15 - Pranav Patil, Sai Prerana Mandalika, Zenan Wang">
<meta name="dcterms.date" content="2025-04-29">

<title>DataMorph: Data Engineering AI Agent</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="report_files/libs/clipboard/clipboard.min.js"></script>
<script src="report_files/libs/quarto-html/quarto.js"></script>
<script src="report_files/libs/quarto-html/popper.min.js"></script>
<script src="report_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="report_files/libs/quarto-html/anchor.min.js"></script>
<link href="report_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="report_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="report_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="report_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="report_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract"><span class="header-section-number">1</span> Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">2</span> Introduction</a></li>
  <li><a href="#data-source-and-preparation" id="toc-data-source-and-preparation" class="nav-link" data-scroll-target="#data-source-and-preparation"><span class="header-section-number">3</span> Data Source and Preparation</a>
  <ul class="collapse">
  <li><a href="#preprocessing-strategy" id="toc-preprocessing-strategy" class="nav-link" data-scroll-target="#preprocessing-strategy"><span class="header-section-number">3.1</span> Preprocessing Strategy</a></li>
  <li><a href="#justification-for-dataset-selection" id="toc-justification-for-dataset-selection" class="nav-link" data-scroll-target="#justification-for-dataset-selection"><span class="header-section-number">3.2</span> Justification for Dataset Selection</a></li>
  </ul></li>
  <li><a href="#retrieval-augmented-generation-rag" id="toc-retrieval-augmented-generation-rag" class="nav-link" data-scroll-target="#retrieval-augmented-generation-rag"><span class="header-section-number">4</span> Retrieval-Augmented Generation (RAG)</a>
  <ul class="collapse">
  <li><a href="#architecture-and-role-in-the-pipeline" id="toc-architecture-and-role-in-the-pipeline" class="nav-link" data-scroll-target="#architecture-and-role-in-the-pipeline"><span class="header-section-number">4.1</span> Architecture and Role in the Pipeline</a></li>
  <li><a href="#implementation-details" id="toc-implementation-details" class="nav-link" data-scroll-target="#implementation-details"><span class="header-section-number">4.2</span> Implementation Details</a></li>
  </ul></li>
  <li><a href="#agents" id="toc-agents" class="nav-link" data-scroll-target="#agents"><span class="header-section-number">5</span> Agents</a>
  <ul class="collapse">
  <li><a href="#deserialization-agent" id="toc-deserialization-agent" class="nav-link" data-scroll-target="#deserialization-agent"><span class="header-section-number">5.1</span> Deserialization Agent</a></li>
  <li><a href="#schema-inference-agent" id="toc-schema-inference-agent" class="nav-link" data-scroll-target="#schema-inference-agent"><span class="header-section-number">5.2</span> Schema Inference Agent</a></li>
  <li><a href="#transformation-agent" id="toc-transformation-agent" class="nav-link" data-scroll-target="#transformation-agent"><span class="header-section-number">5.3</span> Transformation Agent</a></li>
  <li><a href="#serialization-agent" id="toc-serialization-agent" class="nav-link" data-scroll-target="#serialization-agent"><span class="header-section-number">5.4</span> Serialization Agent</a></li>
  <li><a href="#convert-file-agent" id="toc-convert-file-agent" class="nav-link" data-scroll-target="#convert-file-agent"><span class="header-section-number">5.5</span> Convert File Agent</a></li>
  <li><a href="#upload-s3-agent" id="toc-upload-s3-agent" class="nav-link" data-scroll-target="#upload-s3-agent"><span class="header-section-number">5.6</span> Upload S3 Agent</a></li>
  </ul></li>
  <li><a href="#evaluation-of-effectiveness" id="toc-evaluation-of-effectiveness" class="nav-link" data-scroll-target="#evaluation-of-effectiveness"><span class="header-section-number">6</span> Evaluation of Effectiveness</a>
  <ul class="collapse">
  <li><a href="#quantitative-results" id="toc-quantitative-results" class="nav-link" data-scroll-target="#quantitative-results"><span class="header-section-number">6.1</span> Quantitative Results</a></li>
  <li><a href="#latency" id="toc-latency" class="nav-link" data-scroll-target="#latency"><span class="header-section-number">6.2</span> Latency</a></li>
  <li><a href="#accuracy-and-output-quality" id="toc-accuracy-and-output-quality" class="nav-link" data-scroll-target="#accuracy-and-output-quality"><span class="header-section-number">6.3</span> Accuracy and Output Quality</a></li>
  <li><a href="#faithfulness-metric-limitation" id="toc-faithfulness-metric-limitation" class="nav-link" data-scroll-target="#faithfulness-metric-limitation"><span class="header-section-number">6.4</span> Faithfulness Metric Limitation</a></li>
  </ul></li>
  <li><a href="#responsible-ai-considerations" id="toc-responsible-ai-considerations" class="nav-link" data-scroll-target="#responsible-ai-considerations"><span class="header-section-number">7</span> Responsible AI Considerations</a>
  <ul class="collapse">
  <li><a href="#bias-and-fairness" id="toc-bias-and-fairness" class="nav-link" data-scroll-target="#bias-and-fairness"><span class="header-section-number">7.1</span> Bias and Fairness</a></li>
  <li><a href="#hallucination-control" id="toc-hallucination-control" class="nav-link" data-scroll-target="#hallucination-control"><span class="header-section-number">7.2</span> Hallucination Control</a></li>
  <li><a href="#privacy-and-security" id="toc-privacy-and-security" class="nav-link" data-scroll-target="#privacy-and-security"><span class="header-section-number">7.3</span> Privacy and Security</a></li>
  <li><a href="#ethical-design" id="toc-ethical-design" class="nav-link" data-scroll-target="#ethical-design"><span class="header-section-number">7.4</span> Ethical Design</a></li>
  </ul></li>
  <li><a href="#findings-and-insights" id="toc-findings-and-insights" class="nav-link" data-scroll-target="#findings-and-insights"><span class="header-section-number">8</span> Findings and Insights</a>
  <ul class="collapse">
  <li><a href="#key-insights" id="toc-key-insights" class="nav-link" data-scroll-target="#key-insights"><span class="header-section-number">8.1</span> Key Insights</a></li>
  <li><a href="#unexpected-challenges" id="toc-unexpected-challenges" class="nav-link" data-scroll-target="#unexpected-challenges"><span class="header-section-number">8.2</span> Unexpected Challenges</a></li>
  </ul></li>
  <li><a href="#demo" id="toc-demo" class="nav-link" data-scroll-target="#demo"><span class="header-section-number">9</span> Demo</a></li>
  <li><a href="#conclusion-and-future-work" id="toc-conclusion-and-future-work" class="nav-link" data-scroll-target="#conclusion-and-future-work"><span class="header-section-number">10</span> Conclusion and Future Work</a>
  <ul class="collapse">
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">10.1</span> Summary</a></li>
  <li><a href="#future-roadmap" id="toc-future-roadmap" class="nav-link" data-scroll-target="#future-roadmap"><span class="header-section-number">10.2</span> Future Roadmap</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">11</span> References</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">DataMorph: Data Engineering AI Agent</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Group 15 - Pranav Patil, Sai Prerana Mandalika, Zenan Wang </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 29, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="abstract" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="abstract"><span class="header-section-number">1</span> Abstract</h2>
<p>In today’s data-centric world, organizations across sectors such as finance, healthcare, and e-commerce must manage increasingly heterogeneous data sources. These datasets often arrive in formats like JSON, CSV, XML, Avro, and Parquet, each with distinct structural characteristics and schema definitions. The Extract, Transform, Load (ETL) process required to integrate such data is typically manual, time-consuming, and prone to error. As a result, maintaining ETL pipelines becomes a substantial operational overhead, particularly when dealing with schema evolution, nested structures, and unstructured or semi-structured inputs.</p>
<p>To address these challenges, this project introduces <strong>DataMorph</strong>, a generative AI-powered data engineering framework that autonomously executes the ETL workflow using intelligent agents. DataMorph combines modular agent orchestration via LangGraph with Retrieval-Augmented Generation (RAG) to produce a context-aware, self-adaptive ETL system. Through LLMs such as GPT-4 and embedding-based retrieval with ChromaDB, the system dynamically generates parsing, transformation, and serialization code tailored to the user’s natural language prompts.</p>
<p>The final implementation consists of a user-friendly Streamlit interface and six functional agents—Deserialization, Schema Inference, Transformation, Serialization, Format Conversion, and S3 Upload. Our system demonstrates robust performance across 50 test cases, with a 76% success rate and an average per-agent response latency of 2.3 seconds. The findings suggest that GenAI can significantly reduce the burden of manual data handling, with potential for real-world deployment in automated data pipelines. This report documents the complete lifecycle of the system, from conceptualization and architecture design to implementation, evaluation, and deployment.</p>
<hr>
</section>
<section id="introduction" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="introduction"><span class="header-section-number">2</span> Introduction</h2>
<p>As organizations continue to accumulate large volumes of data from diverse sources, the demand for scalable, intelligent data integration workflows has intensified. Traditional ETL processes rely heavily on hand-coded scripts or legacy pipeline builders that are not only rigid but also ill-equipped to handle schema drift, nested data formats, or evolving compliance requirements. Moreover, these solutions lack the flexibility to adapt to new file structures without developer intervention, making them brittle and inefficient in dynamic data environments.</p>
<p>Recent advancements in Generative AI, particularly the development of highly capable Large Language Models (LLMs), provide a new avenue for automating traditionally manual processes in data engineering. These models possess the capacity to reason about structured and unstructured data, generate executable transformation logic, and respond adaptively to context-rich prompts. However, their integration into robust, modular systems for real-world ETL use cases remains relatively underexplored.</p>
<p>Our project, <strong>DataMorph</strong>, seeks to address this gap by developing a fully functional, multi-agent GenAI system capable of autonomously executing end-to-end ETL tasks. We investigate three central research questions: 1. Can LLMs reliably infer schema and transform heterogeneous data formats based on natural language instructions? 2. How can multi-agent frameworks like LangGraph improve modularity, fault tolerance, and extensibility in ETL pipelines? 3. What are the measurable benefits of using Retrieval-Augmented Generation (RAG) to ground LLM outputs in external knowledge?</p>
<p>The solution is designed to provide users with a seamless interface for uploading data, issuing transformation requests, and retrieving standardized outputs—all with minimal human intervention. The broader goal is to shift the paradigm of data engineering from manual code writing to intelligent, declarative automation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/datamorph.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure 1: DataMorph: Data Engineering AI Agent</figcaption>
</figure>
</div>
<hr>
</section>
<section id="data-source-and-preparation" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="data-source-and-preparation"><span class="header-section-number">3</span> Data Source and Preparation</h2>
<p>To ensure the generalizability of our solution, we collected a diverse set of data files encompassing various formats and structural complexities. The selected formats include: - <strong>CSV</strong>: Flat, tabular files commonly used in business analytics. - <strong>JSON</strong>: Semi-structured data with nested fields. - <strong>XML</strong>: Hierarchical structures typically used in government and healthcare. - <strong>Parquet</strong>: Columnar storage optimized for analytics. - <strong>Excel (.xlsx)</strong>: Widely used in enterprises for record keeping and reporting.</p>
<section id="preprocessing-strategy" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="preprocessing-strategy"><span class="header-section-number">3.1</span> Preprocessing Strategy</h3>
<p>Each file was validated to ensure structural integrity, and sample records were extracted to simulate real-world transformation scenarios. For instance, JSON files with deeply nested objects were included to test parsing capabilities, and CSV files with inconsistent headers were used to test schema inference robustness. Data previews (first 10–20 rows) were captured to help the LLM understand the file’s structure and assist in prompt conditioning.</p>
</section>
<section id="justification-for-dataset-selection" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="justification-for-dataset-selection"><span class="header-section-number">3.2</span> Justification for Dataset Selection</h3>
<p>The selected formats and sources reflect the diversity found in real-world enterprise data ecosystems. Testing the agents against these various formats allowed us to validate the flexibility and generalization ability of the GenAI-driven architecture under a wide range of edge cases and data idiosyncrasies.</p>
<hr>
</section>
</section>
<section id="retrieval-augmented-generation-rag" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="retrieval-augmented-generation-rag"><span class="header-section-number">4</span> Retrieval-Augmented Generation (RAG)</h2>
<section id="architecture-and-role-in-the-pipeline" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="architecture-and-role-in-the-pipeline"><span class="header-section-number">4.1</span> Architecture and Role in the Pipeline</h3>
<p>RAG plays a foundational role in the transformation agent by embedding external domain knowledge into the prompt space of the LLM. Instead of relying purely on the language model’s intrinsic knowledge, which may be incomplete or outdated, RAG injects curated content relevant to the task at hand—whether that is normalizing date formats, dealing with null values, or serializing to a specific file type.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/rag_flow.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure 2: Retrieval-Augmented Generation (RAG) Workflow for Data Cleaning</figcaption>
</figure>
</div>
<p>The diagram outlines how the system retrieves relevant domain knowledge from a vector database, combines it with the user’s transformation instruction and a preview of the dataset, and constructs a composite prompt. This prompt is sent to an LLM, which returns executable code tailored for schema-aware, context-sensitive transformations.</p>
</section>
<section id="implementation-details" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="implementation-details"><span class="header-section-number">4.2</span> Implementation Details</h3>
<ul>
<li><strong>Knowledge Base</strong>: A curated set of domain-specific text files, each containing transformation best practices (e.g., “Handling missing values in finance datasets”, “XML schema normalization”).</li>
<li><strong>Retriever</strong>: Initially implemented as keyword-overlap matching, later extended with <strong>ChromaDB</strong>, a vector-based semantic search engine that improves recall and relevance.</li>
<li><strong>Prompt Construction</strong>: Combines three primary elements:
<ol type="1">
<li>The user’s transformation request</li>
<li>A data preview of the file</li>
<li>Relevant knowledge snippets retrieved from the vector store</li>
</ol></li>
</ul>
<p>This structured approach enables context-aware generation, where the LLM can reason both from user intent and external domain expertise.</p>
<hr>
</section>
</section>
<section id="agents" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="agents"><span class="header-section-number">5</span> Agents</h2>
<p>Each functional unit within DataMorph is represented as an agent in the LangGraph framework. Agents operate asynchronously and are stateless, sharing information via a persistent dictionary structure (<code>state</code>) that evolves across the pipeline. This design promotes scalability and modularity, allowing developers to add or replace agents without affecting the entire system.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/agents_used.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure 3: Overview of Functional Agents in DataMorph</figcaption>
</figure>
</div>
<p>This schematic provides a high-level view of the six modular agents—Deserialization, Schema Inference, Transformation, Serialization, Format Conversion, and S3 Upload. Each agent operates independently within the LangGraph pipeline and is responsible for one core ETL task, promoting reusability and fault isolation.</p>
<section id="deserialization-agent" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="deserialization-agent"><span class="header-section-number">5.1</span> Deserialization Agent</h3>
<ul>
<li>Automatically detects file format and generates loading code.</li>
<li>For example, nested JSON structures are parsed using <code>json.load()</code> instead of naive <code>pd.read_json()</code>.</li>
</ul>
</section>
<section id="schema-inference-agent" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="schema-inference-agent"><span class="header-section-number">5.2</span> Schema Inference Agent</h3>
<ul>
<li>Uses Pandas to extract column names and types.</li>
<li>Generates a standardized JSON schema used downstream for validation and transformation.</li>
</ul>
</section>
<section id="transformation-agent" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="transformation-agent"><span class="header-section-number">5.3</span> Transformation Agent</h3>
<ul>
<li>Most complex agent. Constructs composite prompts with RAG-enriched context.</li>
<li>Uses LLM to generate transformation code that is both syntactically valid and semantically aligned with the schema.</li>
</ul>
</section>
<section id="serialization-agent" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="serialization-agent"><span class="header-section-number">5.4</span> Serialization Agent</h3>
<ul>
<li>Converts transformed DataFrame into the target output format.</li>
<li>Applies best practices for data serialization based on format (e.g., indentation for JSON, compression for Parquet).</li>
</ul>
</section>
<section id="convert-file-agent" class="level3" data-number="5.5">
<h3 data-number="5.5" class="anchored" data-anchor-id="convert-file-agent"><span class="header-section-number">5.5</span> Convert File Agent</h3>
<ul>
<li>Provides flexibility for post-processing conversion tasks (e.g., converting CSV to Parquet).</li>
</ul>
</section>
<section id="upload-s3-agent" class="level3" data-number="5.6">
<h3 data-number="5.6" class="anchored" data-anchor-id="upload-s3-agent"><span class="header-section-number">5.6</span> Upload S3 Agent</h3>
<ul>
<li>Connects securely to AWS S3 using <code>boto3</code>.</li>
<li>Uploads cleaned files to specified prefixes (<code>/Raw</code>, <code>/Transformed</code>).</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/agent_workflow.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure 4: End-to-End Agent Execution Workflow in LangGraph</figcaption>
</figure>
</div>
<p>This diagram shows the flow of data and control signals across the pipeline. It captures how the system transitions through agent stages, maintains shared state, and selectively routes tasks based on user input and intermediate outcomes, forming a dynamic and adaptive ETL architecture.</p>
<hr>
</section>
</section>
<section id="evaluation-of-effectiveness" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="evaluation-of-effectiveness"><span class="header-section-number">6</span> Evaluation of Effectiveness</h2>
<p>Evaluation is a critical component of validating the real-world applicability and robustness of GenAI-powered systems like DataMorph. To assess its performance, we established a comprehensive evaluation framework that measured the solution across three key dimensions: <strong>latency</strong>, <strong>accuracy</strong>, and <strong>reliability</strong>. Each metric was evaluated using a controlled set of 50 diverse test cases spanning multiple file formats and transformation requirements.</p>
<section id="quantitative-results" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="quantitative-results"><span class="header-section-number">6.1</span> Quantitative Results</h3>
<p><strong>Table 1: Summary of DataMorph Agent Performance</strong></p>
<table class="table">
<thead>
<tr class="header">
<th>Metric</th>
<th>Outcome</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Average Agent Latency</td>
<td>2.3 seconds</td>
</tr>
<tr class="even">
<td>End-to-End Success Rate</td>
<td>76% (38/50 workflows)</td>
</tr>
<tr class="odd">
<td>Valid Output Parsing Rate</td>
<td>90%</td>
</tr>
<tr class="even">
<td>Code Execution Failures</td>
<td>10% (5 cases)</td>
</tr>
<tr class="odd">
<td>Formatting Issues</td>
<td>14% (7 cases)</td>
</tr>
</tbody>
</table>
</section>
<section id="latency" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="latency"><span class="header-section-number">6.2</span> Latency</h3>
<p>Agent latency was calculated as the average time taken by each modular agent to complete its function. Results indicated efficient execution across all agents, with deserialization and schema inference agents consistently completing in under 2 seconds, while serialization and cloud upload incurred marginal delays due to I/O operations.</p>
</section>
<section id="accuracy-and-output-quality" class="level3" data-number="6.3">
<h3 data-number="6.3" class="anchored" data-anchor-id="accuracy-and-output-quality"><span class="header-section-number">6.3</span> Accuracy and Output Quality</h3>
<p>The pipeline was deemed successful if the final transformed file: - Conformed to user-specified transformation logic - Passed schema and parsing checks using <code>pandas</code> - Retained data integrity (e.g., row/column counts matched expected values)</p>
<p>Failures primarily stemmed from ambiguities in user prompts or non-standard nested data structures, especially in XML and JSON formats.</p>
</section>
<section id="faithfulness-metric-limitation" class="level3" data-number="6.4">
<h3 data-number="6.4" class="anchored" data-anchor-id="faithfulness-metric-limitation"><span class="header-section-number">6.4</span> Faithfulness Metric Limitation</h3>
<p>While ‘faithfulness’ is a common metric in evaluating LLM outputs, it falls short in the context of code generation. Many valid transformations can be implemented in multiple ways, none of which may closely resemble the retrieved context from RAG. As a result, faithfulness scores may be misleading. Instead, we prioritized <strong>execution correctness</strong> and <strong>output conformity</strong> as primary indicators of success.</p>
<hr>
</section>
</section>
<section id="responsible-ai-considerations" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="responsible-ai-considerations"><span class="header-section-number">7</span> Responsible AI Considerations</h2>
<p>As GenAI systems become increasingly embedded in data workflows, it is essential to evaluate their ethical implications, particularly in sensitive contexts like healthcare or finance.</p>
<section id="bias-and-fairness" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="bias-and-fairness"><span class="header-section-number">7.1</span> Bias and Fairness</h3>
<p>The system does not train on or infer user-level attributes, reducing the risk of demographic or representational bias. Nonetheless, the source data and pre-trained LLMs may carry inherent biases, necessitating regular audits.</p>
</section>
<section id="hallucination-control" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="hallucination-control"><span class="header-section-number">7.2</span> Hallucination Control</h3>
<p>To minimize hallucinations (i.e., plausible-sounding but incorrect outputs), we: - Used RAG to provide real-world context - Structured prompts to constrain the generation space - Tested LLM responses against validation rules post-generation</p>
</section>
<section id="privacy-and-security" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="privacy-and-security"><span class="header-section-number">7.3</span> Privacy and Security</h3>
<p>No user data is stored permanently. For production use, we propose integrating: - Named Entity Recognition (NER) to identify PII - Regex-based redaction routines before serialization</p>
</section>
<section id="ethical-design" class="level3" data-number="7.4">
<h3 data-number="7.4" class="anchored" data-anchor-id="ethical-design"><span class="header-section-number">7.4</span> Ethical Design</h3>
<p>The system is intended to augment human engineers rather than replace them. By automating repetitive and mechanical aspects of ETL, we aim to free up human time for more strategic tasks such as data interpretation and insight generation.</p>
<hr>
</section>
</section>
<section id="findings-and-insights" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="findings-and-insights"><span class="header-section-number">8</span> Findings and Insights</h2>
<section id="key-insights" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="key-insights"><span class="header-section-number">8.1</span> Key Insights</h3>
<ul>
<li><strong>Agentic Modularity</strong> enabled rapid debugging, iterative development, and potential parallel execution in future versions.</li>
<li><strong>RAG Integration</strong> significantly improved instruction-following capabilities of LLMs, especially for domain-specific data like healthcare or finance.</li>
<li><strong>Single File Limitation</strong> constrained broader workflows but revealed promising paths for batch processing in future iterations.</li>
</ul>
</section>
<section id="unexpected-challenges" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="unexpected-challenges"><span class="header-section-number">8.2</span> Unexpected Challenges</h3>
<ul>
<li>Handling deeply nested or inconsistent schemas proved difficult, requiring better schema reasoning mechanisms.</li>
<li>LLMs sometimes ignored critical context when prompt lengths exceeded token limits, especially with large data previews.</li>
</ul>
<hr>
</section>
</section>
<section id="demo" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="demo"><span class="header-section-number">9</span> Demo</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://youtu.be/nRUqC8aI3KY"><img src="images/demo_thumbnail.png" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption">Figure 5: Streamlit Interface Demonstrating the DataMorph Pipeline</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p>🎥 Click the thumbnail above or <a href="https://youtu.be/nRUqC8aI3KY">watch the demo directly on YouTube</a></p>
</blockquote>
<p>The demonstration includes:</p>
<ul>
<li><p>A walkthrough of the Streamlit UI, showcasing file upload, prompt entry, and agent execution</p></li>
<li><p>Visualization of intermediate steps: schema inference, transformation preview, and upload status</p></li>
</ul>
<hr>
</section>
<section id="conclusion-and-future-work" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="conclusion-and-future-work"><span class="header-section-number">10</span> Conclusion and Future Work</h2>
<p>DataMorph successfully illustrates how GenAI, when paired with modular architectures and external context retrieval, can automate and scale ETL processes that traditionally required significant manual engineering.</p>
<section id="summary" class="level3" data-number="10.1">
<h3 data-number="10.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">10.1</span> Summary</h3>
<ul>
<li>Integrated GPT-4, RAG, and LangGraph to build a fault-tolerant, extensible pipeline</li>
<li>Achieved 76% automation success rate over diverse input formats</li>
<li>Validated design with rigorous latency, accuracy, and formatting tests</li>
</ul>
</section>
<section id="future-roadmap" class="level3" data-number="10.2">
<h3 data-number="10.2" class="anchored" data-anchor-id="future-roadmap"><span class="header-section-number">10.2</span> Future Roadmap</h3>
<ul>
<li><strong>Multi-file Upload &amp; Merging</strong>: Enable cross-file transformations</li>
<li><strong>Schema Drift Detection</strong>: Highlight evolving schemas over time for audit use cases</li>
<li><strong>Guardrails for Sensitive Data</strong>: Implement regex and LLM redaction tools for PII</li>
<li><strong>Complex Format Handling</strong>: Improved support for nested XML/Parquet schemas</li>
<li><strong>Self-Correction Loop</strong>: Train a feedback mechanism to learn from prior errors and update transformation strategies dynamically</li>
<li><strong>CI/CD &amp; Containerization</strong>: Enable scalable deployments via Docker and GitHub Actions</li>
</ul>
<hr>
</section>
</section>
<section id="references" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="references"><span class="header-section-number">11</span> References</h2>
<ul>
<li>LangGraph: https://github.com/langchain-ai/langgraph</li>
<li>TotalEnergies Blog on GenAI for ETL : https://youtu.be/T23Bs75F7ZQ?feature=shared</li>
<li>Cognizant Insights: https://www.cognizant.com/us/en/insights</li>
<li>Medium article: Advancing Data Engineering with GenAI : https://medium.com/totalenergies-digital-factory/advancing-data-engineering-with-generative-ai-cb8c6c3b1b1e</li>
</ul>
<hr>
<p><em>Report authored by Group 15: Pranav Patil, Sai Prerana Mandalika, Zenan Wang — for DSAN 6725, Spring 2025.</em></p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>